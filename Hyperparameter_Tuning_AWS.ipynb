{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.predictor import csv_serializer\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAMEO_DEU_2015_MAP = {\n",
    "    '1A': 1,\n",
    "    '1B': 1,\n",
    "    '1C': 1,\n",
    "    '1D': 1,\n",
    "    '1E': 1,\n",
    "    '2A': 2,\n",
    "    '2B': 2,\n",
    "    '2C': 2,\n",
    "    '2D': 2,\n",
    "    '3A': 3,\n",
    "    '3B': 3,\n",
    "    '3C': 3,\n",
    "    '3D': 3,\n",
    "    '4A': 4,\n",
    "    '4B': 4,\n",
    "    '4C': 4,\n",
    "    '4D': 4,\n",
    "    '4E': 4,\n",
    "    '5A': 5,\n",
    "    '5B': 5,\n",
    "    '5C': 5,\n",
    "    '5D': 5,\n",
    "    '5E': 5,\n",
    "    '5F': 5,\n",
    "    '6A': 6,\n",
    "    '6B': 6,\n",
    "    '6C': 6,\n",
    "    '6D': 6,\n",
    "    '6E': 6,\n",
    "    '6F': 6,\n",
    "    '7A': 7,\n",
    "    '7B': 7,\n",
    "    '7C': 7,\n",
    "    '7D': 7,\n",
    "    '7E': 7,\n",
    "    '8A': 8,\n",
    "    '8B': 8,\n",
    "    '8C': 8,\n",
    "    '8D': 8,\n",
    "    '9A': 9,\n",
    "    '9B': 9,\n",
    "    '9C': 9,\n",
    "    '9D': 9,\n",
    "    '9E': 9\n",
    "}\n",
    "\n",
    "PRAEGENDE_JUGENDJAHRE_MAP = {\n",
    "    1: 0,\n",
    "    2: 1,\n",
    "    3: 0,\n",
    "    4: 1,\n",
    "    5: 0,\n",
    "    6: 1,\n",
    "    7: 1,\n",
    "    8: 0,\n",
    "    9: 1,\n",
    "    10: 0,\n",
    "    11: 1,\n",
    "    12: 0,\n",
    "    13: 1,\n",
    "    14: 0,\n",
    "    15: 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70876, 9)\n",
      "(42962, 366)\n",
      "(42833, 365)\n",
      "(312, 8)\n"
     ]
    }
   ],
   "source": [
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "interactions_key = 'udacity-capstone/data/interactions.csv'\n",
    "train_location = 's3://{}/{}'.format(bucket, interactions_key)\n",
    "interactions_df = pd.read_csv(train_location)\n",
    "print(interactions_df.shape)\n",
    "\n",
    "train_data_key = 'udacity-capstone/data/Udacity_MAILOUT_052018_TRAIN.csv'\n",
    "train_location = 's3://{}/{}'.format(bucket, train_data_key)\n",
    "train_df = pd.read_csv(train_location, sep=';', index_col='LNR')\n",
    "print(train_df.shape)\n",
    "\n",
    "\n",
    "test_data_key = 'udacity-capstone/data/Udacity_MAILOUT_052018_TEST.csv'\n",
    "test_location = 's3://{}/{}'.format(bucket, test_data_key)\n",
    "test_df = pd.read_csv(test_location, sep=';', index_col='LNR')\n",
    "print(test_df.shape)\n",
    "\n",
    "\n",
    "metadata_data_key = 'udacity-capstone/data/metadata.csv'\n",
    "metadata_location = 's3://{}/{}'.format(bucket, metadata_data_key)\n",
    "metadata = pd.read_csv(metadata_location)\n",
    "print(metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_order(val, mx, mn):\n",
    "    diff_from_low = val - mn \n",
    "    return mx - diff_from_low\n",
    "\n",
    "\n",
    "def default_clean(df, drop_threshold=20, testing=False):\n",
    "    df_ = df.copy()\n",
    "    \n",
    "    print('initial df shape: ', df_.shape)\n",
    "    keep_features = list(metadata[metadata['keep'] == 1]['feature_name'])\n",
    "    if 'RESPONSE' in df.columns:\n",
    "        keep_features.append('RESPONSE')\n",
    "    df_ = df_[keep_features]\n",
    "    \n",
    "    filter_ = df_['CAMEO_DEUG_2015'] != np.nan\n",
    "    df_.loc[filter_, 'CAMEO_DEUG_2015'] = pd.to_numeric(df_.loc[filter_, 'CAMEO_DEUG_2015'], errors='coerce')\n",
    "    \n",
    "    # set zero to negative one where zero means unknown\n",
    "    unknown_zero_features = list(metadata[metadata['unknown_zero'] == 1]['feature_name'])\n",
    "    for feature in unknown_zero_features:\n",
    "        df_.loc[df_[feature] == 0, feature] = -1\n",
    "        \n",
    "    # set nine to negative one where nine means unknown\n",
    "    unknown_nine_features = list(metadata[metadata['unknown_nine'] == 1]['feature_name'])\n",
    "    for feature in unknown_nine_features:\n",
    "        df_.loc[df_[feature] == 9, feature] = -1\n",
    "        \n",
    "        \n",
    "    # special cases\n",
    "    df_['CAMEO_DEUG_2015'].replace('X', np.nan, inplace=True)\n",
    "    #df_['OST_WEST_KZ'].replace('O', 1, inplace=True)\n",
    "    #df_['OST_WEST_KZ'].replace('W', 0, inplace=True)    \n",
    "    df_['CAMEO_DEU_2015'] = df_['CAMEO_DEU_2015'].apply(lambda x: x if x in CAMEO_DEU_2015_MAP else np.nan)\n",
    "    df_['PRAEGENDE_JUGENDJAHRE'] = df_['PRAEGENDE_JUGENDJAHRE'].apply(lambda x: PRAEGENDE_JUGENDJAHRE_MAP[x] if x in PRAEGENDE_JUGENDJAHRE_MAP else np.nan)\n",
    "    \n",
    "    # set -1 (unknown) to np.nan\n",
    "    df_ = df_.replace(-1, np.nan)\n",
    "    \n",
    "    \n",
    "    # change some numerical columns to categorical for one hot encoding:\n",
    "    cat_cols = list(metadata.loc[(metadata['type'] == 'categorical') & (metadata['keep'] == 1), 'feature_name'])\n",
    "    print('cat_cols: ', cat_cols)\n",
    "    for col in cat_cols:\n",
    "        if col in df_.columns:\n",
    "            df_[col] = np.where(df_[col].isnull(), df_[col], df_[col].astype('str'))\n",
    "    df_ = pd.get_dummies(df_, prefix=cat_cols, columns=cat_cols)\n",
    "    \n",
    "    # reverse some cols so higher number = higher feature\n",
    "    reverse_cols = list(metadata.loc[metadata['needs_reverse']==1, 'feature_name'])\n",
    "    for col in reverse_cols:\n",
    "        if col in df_.columns:\n",
    "            series = df_[col]\n",
    "            df_[col] = df_[col].apply(reverse_order, args=(np.max(series), np.min(series)))\n",
    "            \n",
    "            \n",
    "    percent_missing = df_.isnull().sum() * 100 / len(df)\n",
    "    mv_df = pd.DataFrame({'column_name': df_.columns, 'percent_missing': percent_missing})\n",
    "    mv_cols = mv_df.loc[mv_df['percent_missing'] > drop_threshold]['column_name']    \n",
    "    df_ = df_.drop(list(mv_cols), axis=1)\n",
    "    \n",
    "    if False:\n",
    "        thresh = int(len(df_.columns) * 0.85)\n",
    "        if 'RESPONSE' in df_.columns:\n",
    "            grouped = df_.groupby(df_.RESPONSE)\n",
    "            pos = grouped.get_group(1)\n",
    "            neg = grouped.get_group(0)\n",
    "            neg = neg.dropna(thresh=thresh)\n",
    "            df_  = neg.append(pos, verify_integrity=True, ignore_index=False)\n",
    "        else:\n",
    "            df_ = df_.dropna(thresh=thresh)\n",
    "        \n",
    "    #df_ = df_.loc[:, ~df_.columns.str.startswith('KB')]\n",
    "    \n",
    "    print('new df shape: ', df_.shape)\n",
    "    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532\n",
      "initial df shape:  (42962, 366)\n",
      "cat_cols:  ['ANREDE_KZ', 'CAMEO_DEU_2015', 'D19_KONSUMTYP', 'GEBAEUDETYP', 'GEBAEUDETYP_RASTER', 'GFK_URLAUBERTYP', 'GREEN_AVANTGARDE', 'HEALTH_TYP', 'KBA05_HERSTTEMP', 'KBA05_MAXHERST', 'KBA05_MODTEMP', 'KBA05_SEG6', 'KONSUMNAEHE', 'NATIONALITAET_KZ', 'OST_WEST_KZ', 'TITEL_KZ', 'VERS_TYP', 'ZABEOTYP']\n",
      "new df shape:  (42962, 376)\n",
      "initial df shape:  (42833, 365)\n",
      "cat_cols:  ['ANREDE_KZ', 'CAMEO_DEU_2015', 'D19_KONSUMTYP', 'GEBAEUDETYP', 'GEBAEUDETYP_RASTER', 'GFK_URLAUBERTYP', 'GREEN_AVANTGARDE', 'HEALTH_TYP', 'KBA05_HERSTTEMP', 'KBA05_MAXHERST', 'KBA05_MODTEMP', 'KBA05_SEG6', 'KONSUMNAEHE', 'NATIONALITAET_KZ', 'OST_WEST_KZ', 'TITEL_KZ', 'VERS_TYP', 'ZABEOTYP']\n",
      "new df shape:  (42833, 375)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.sum(train_df['RESPONSE'] == 1))\n",
    "train_df_init = default_clean(train_df, drop_threshold=80)\n",
    "test_df_init = default_clean(test_df, drop_threshold=80, testing=True)\n",
    "np.sum(train_df_init['RESPONSE'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>composition</th>\n",
       "      <th>mu0</th>\n",
       "      <th>mu1</th>\n",
       "      <th>se0</th>\n",
       "      <th>se1</th>\n",
       "      <th>sd</th>\n",
       "      <th>mu_diff</th>\n",
       "      <th>stds_between</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGER_TYP</td>\n",
       "      <td>1</td>\n",
       "      <td>1.698736</td>\n",
       "      <td>1.712991</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>0.035510</td>\n",
       "      <td>0.035761</td>\n",
       "      <td>0.014255</td>\n",
       "      <td>0.398631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALTERSKATEGORIE_GROB</td>\n",
       "      <td>1</td>\n",
       "      <td>3.513077</td>\n",
       "      <td>3.235405</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>0.045459</td>\n",
       "      <td>0.045653</td>\n",
       "      <td>0.277672</td>\n",
       "      <td>6.082289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALTER_HH</td>\n",
       "      <td>1</td>\n",
       "      <td>12.431288</td>\n",
       "      <td>11.658470</td>\n",
       "      <td>0.025466</td>\n",
       "      <td>0.210338</td>\n",
       "      <td>0.211874</td>\n",
       "      <td>0.772818</td>\n",
       "      <td>3.647532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANZ_HAUSHALTE_AKTIV</td>\n",
       "      <td>1</td>\n",
       "      <td>6.652886</td>\n",
       "      <td>5.831435</td>\n",
       "      <td>0.081977</td>\n",
       "      <td>0.569530</td>\n",
       "      <td>0.575400</td>\n",
       "      <td>0.821451</td>\n",
       "      <td>1.427617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANZ_HH_TITEL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048276</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.014012</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>0.018391</td>\n",
       "      <td>1.298842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature  composition        mu0        mu1       se0  \\\n",
       "0              AGER_TYP            1   1.698736   1.712991  0.004230   \n",
       "1  ALTERSKATEGORIE_GROB            1   3.513077   3.235405  0.004203   \n",
       "2              ALTER_HH            1  12.431288  11.658470  0.025466   \n",
       "3   ANZ_HAUSHALTE_AKTIV            1   6.652886   5.831435  0.081977   \n",
       "4          ANZ_HH_TITEL            1   0.048276   0.066667  0.002037   \n",
       "\n",
       "        se1        sd   mu_diff  stds_between  \n",
       "0  0.035510  0.035761  0.014255      0.398631  \n",
       "1  0.045459  0.045653  0.277672      6.082289  \n",
       "2  0.210338  0.211874  0.772818      3.647532  \n",
       "3  0.569530  0.575400  0.821451      1.427617  \n",
       "4  0.014012  0.014159  0.018391      1.298842  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = interactions_df.copy()\n",
    "df['scaled_diff'] = df['stds_between'] \n",
    "df.loc[df['composition']==2, 'scaled_diff'] = np.sqrt(df.loc[df['composition']==2,'scaled_diff'])\n",
    "df = df.sort_values('scaled_diff', ascending=False)\n",
    "scaled_interactions_df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>composition</th>\n",
       "      <th>mu0</th>\n",
       "      <th>mu1</th>\n",
       "      <th>se0</th>\n",
       "      <th>se1</th>\n",
       "      <th>sd</th>\n",
       "      <th>mu_diff</th>\n",
       "      <th>stds_between</th>\n",
       "      <th>scaled_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D19_KONSUMTYP_9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.179843</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.008053</td>\n",
       "      <td>0.008321</td>\n",
       "      <td>0.144129</td>\n",
       "      <td>17.320914</td>\n",
       "      <td>17.320914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KBA05_SEG6_0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.863580</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.020794</td>\n",
       "      <td>0.020878</td>\n",
       "      <td>0.220722</td>\n",
       "      <td>10.572170</td>\n",
       "      <td>10.572170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NATIONALITAET_KZ_1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956607</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.017272</td>\n",
       "      <td>0.017308</td>\n",
       "      <td>0.153975</td>\n",
       "      <td>8.896222</td>\n",
       "      <td>8.896222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FINANZ_UNAUFFAELLIGER</td>\n",
       "      <td>1</td>\n",
       "      <td>4.324496</td>\n",
       "      <td>3.766917</td>\n",
       "      <td>0.005152</td>\n",
       "      <td>0.062659</td>\n",
       "      <td>0.062870</td>\n",
       "      <td>0.557579</td>\n",
       "      <td>8.868726</td>\n",
       "      <td>8.868726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEMIO_REL</td>\n",
       "      <td>1</td>\n",
       "      <td>5.228081</td>\n",
       "      <td>4.582707</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.090337</td>\n",
       "      <td>0.090727</td>\n",
       "      <td>0.645374</td>\n",
       "      <td>7.113352</td>\n",
       "      <td>7.113352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature  composition       mu0       mu1       se0       se1  \\\n",
       "0      D19_KONSUMTYP_9.0            1  0.179843  0.035714  0.002094  0.008053   \n",
       "1         KBA05_SEG6_0.0            1  0.863580  0.642857  0.001871  0.020794   \n",
       "2   NATIONALITAET_KZ_1.0            1  0.956607  0.802632  0.001111  0.017272   \n",
       "3  FINANZ_UNAUFFAELLIGER            1  4.324496  3.766917  0.005152  0.062659   \n",
       "4              SEMIO_REL            1  5.228081  4.582707  0.008403  0.090337   \n",
       "\n",
       "         sd   mu_diff  stds_between  scaled_diff  \n",
       "0  0.008321  0.144129     17.320914    17.320914  \n",
       "1  0.020878  0.220722     10.572170    10.572170  \n",
       "2  0.017308  0.153975      8.896222     8.896222  \n",
       "3  0.062870  0.557579      8.868726     8.868726  \n",
       "4  0.090727  0.645374      7.113352     7.113352  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_interactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(n):\n",
    "    return scaled_interactions_df.loc[0:n,['feature', 'composition']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_sets(top_n=None):\n",
    "\n",
    "    X_train_full = train_df_init.copy()\n",
    "    y_train_full = X_train_full['RESPONSE']\n",
    "\n",
    "    inter_cols = list(set.intersection(set(X_train_full.columns), set(test_df_init.columns)))\n",
    "\n",
    "    X_train_full = X_train_full[inter_cols]\n",
    "\n",
    "    # \"Cardinality\" means the number of unique values in a column\n",
    "    # Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "    categorical_cols = [cname for cname in X_train_full.columns if\n",
    "                        X_train_full[cname].nunique() < 15 and\n",
    "                        X_train_full[cname].nunique() >= 2 and\n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "\n",
    "    # Select numerical columns\n",
    "    numerical_cols = [cname for cname in X_train_full.columns if \n",
    "                    X_train_full[cname].dtype in ['int64', 'float64', 'uint8']]\n",
    "    \n",
    "    if top_n:\n",
    "        features = get_top_n(top_n)\n",
    "        numerical_cols = []\n",
    "        for ix, row in features.iterrows():\n",
    "            comp = row['composition']\n",
    "            f = row['feature']\n",
    "            if comp == 1 and f in test_df_init.columns and f in train_df_init.columns:\n",
    "                numerical_cols.append(f)\n",
    "            if comp == 2:\n",
    "                fs = f.split(':')\n",
    "                f0 = fs[0]\n",
    "                f1 = fs[1]\n",
    "                if f0 in test_df_init.columns and f0 in train_df_init.columns and f1 in test_df_init and f1 in train_df_init:\n",
    "                    test_df_init[f] = test_df_init[f0] * test_df_init[f1]\n",
    "                    train_df_init[f] = train_df_init[f0] * train_df_init[f1]\n",
    "                    numerical_cols.append(f)\n",
    "                \n",
    "\n",
    "    # Keep selected columns only\n",
    "    my_cols = numerical_cols + categorical_cols\n",
    "\n",
    "    # supervised testing and full datasets\n",
    "    X_test = test_df_init[my_cols].copy()\n",
    "    X_total_train = train_df_init[my_cols].copy()\n",
    "    y_total_train = train_df_init['RESPONSE'].copy()\n",
    "\n",
    "    assert(list(X_total_train.columns) == list(X_test.columns))\n",
    "    \n",
    "    return X_total_train, y_total_train, X_test, numerical_cols, categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42962, 499)\n",
      "(42833, 499)\n"
     ]
    }
   ],
   "source": [
    "X_total_train, y_total_train, X_test, numerical_cols, categorical_cols = get_initial_sets(500)\n",
    "print(X_total_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    #('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC: 0.7307195483278173\n"
     ]
    }
   ],
   "source": [
    "# Define Benchmark Model\n",
    "model = LogisticRegression(class_weight='auto', max_iter=300)\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('scaling', MinMaxScaler()),\n",
    "                              ('pca', PCA(n_components=400)),\n",
    "                              ('model', model)\n",
    "                     ])\n",
    "\n",
    "# Multiply by -1 since sklearn calculates *negative* MAE\n",
    "scores = cross_val_score(my_pipeline, X_total_train, y_total_train,\n",
    "                              cv=5,\n",
    "                              scoring='roc_auc')\n",
    "\n",
    "print('Mean AUC:', scores.mean())\n",
    "\n",
    "# has AUC of 0.6283"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=180, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)\n",
      "Mean AUC: 0.6705251220666832\n",
      "RandomForestClassifier(n_jobs=-1)\n",
      "Mean AUC: 0.5859288638006076\n",
      "BalancedBaggingClassifier()\n",
      "Mean AUC: 0.6014848701812767\n",
      "HistGradientBoostingClassifier()\n",
      "Mean AUC: 0.6042639067414572\n"
     ]
    }
   ],
   "source": [
    "models = [xgb.XGBClassifier(scale_pos_weight=180, n_jobs=-1), RandomForestClassifier(n_jobs=-1), \n",
    "          BalancedBaggingClassifier(), HistGradientBoostingClassifier()]\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    print(model)\n",
    "    my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                  ('model', model)\n",
    "                         ])\n",
    "    \n",
    "    scores = cross_val_score(my_pipeline, X_total_train, y_total_train,\n",
    "                              cv=5,\n",
    "                              scoring='roc_auc')\n",
    "    \n",
    "    print('Mean AUC:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_total_train, y_total_train, test_size=0.33, random_state=42, stratify=y_total_train)\n",
    "X_train.insert(0, column='RESPONSE', value=y_train)\n",
    "X_valid.insert(0, column='RESPONSE', value=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = './data'\n",
    "if not os.path.exists(temp_dir):\n",
    "    os.makedirs(temp_dir)\n",
    "    \n",
    "X_train.to_csv(os.path.join(temp_dir, 'train.csv'), header=False, index=False)\n",
    "X_valid.to_csv(os.path.join(temp_dir, 'validation.csv'), header=False, index=False)\n",
    "X_test.to_csv(os.path.join(temp_dir, 'test.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'udacity-capstone/training-files/clustered-xgboost/final'\n",
    "\n",
    "train_location = session.upload_data(os.path.join(temp_dir, 'train.csv'), key_prefix=prefix)\n",
    "validation_location = session.upload_data(os.path.join(temp_dir, 'validation.csv'), key_prefix=prefix)\n",
    "test_location = session.upload_data(os.path.join(temp_dir, 'test.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'udacity-capstone/training-files/clustered-xgboost/final/output'\n",
    "container = image_uris.retrieve('xgboost', session.boto_region_name, \"1.2-1\")\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(image_uri=container, \n",
    "                                          role=get_execution_role(),\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m4.xlarge', \n",
    "                                          volume_size=5, # 5 GB \n",
    "                                          output_path='s3://{}/{}'.format(bucket, prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        scale_pos_weight=180,\n",
    "                        eta=0.05,\n",
    "                        gamma=4,\n",
    "                        eval_metric='auc',\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='binary:logistic',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_hyperparameter_tuner = HyperparameterTuner(estimator=xgb,\n",
    "                                                objective_metric_name='validation:auc',\n",
    "                                                objective_type='Maximize',\n",
    "                                                max_jobs=200,\n",
    "                                                max_parallel_jobs=4,\n",
    "                                                hyperparameter_ranges={\n",
    "                                                    'max_depth': IntegerParameter(1,15),\n",
    "                                                    'max_delta_step': IntegerParameter(0,10),\n",
    "                                                    'eta': ContinuousParameter(0.05, 0.50),\n",
    "                                                    'min_child_weight': IntegerParameter(2, 100),\n",
    "                                                    'subsample': ContinuousParameter(0.80, 1.00),\n",
    "                                                    'gamma': ContinuousParameter(0, 8),\n",
    "                                                    'lambda': ContinuousParameter(0,1000),\n",
    "                                                    'num_round': IntegerParameter(1,4000),\n",
    "                                                    'alpha': ContinuousParameter(0,1000),\n",
    "                                                    'colsample_bylevel': ContinuousParameter(0.1, 1.00),\n",
    "                                                    'colsample_bynode': ContinuousParameter(0.1, 1.00),\n",
    "                                                    'colsample_bytree': ContinuousParameter(0.5, 1.00)\n",
    "                                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_validation_train = sagemaker.inputs.TrainingInput(s3_data=validation_location, content_type='csv')\n",
    "\n",
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_validation_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-30 02:00:26 Starting - Preparing the instances for training\n",
      "2020-11-30 02:00:26 Downloading - Downloading input data\n",
      "2020-11-30 02:00:26 Training - Training image download completed. Training in progress.\n",
      "2020-11-30 02:00:26 Uploading - Uploading generated training model\n",
      "2020-11-30 02:00:26 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "xgb = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_tuning_objective_metric': 'validation:auc',\n",
       " 'alpha': '439.5109181794774',\n",
       " 'colsample_bylevel': '0.35621991418149157',\n",
       " 'colsample_bynode': '0.12930564658433663',\n",
       " 'colsample_bytree': '0.5604870818559543',\n",
       " 'early_stopping_rounds': '10',\n",
       " 'eta': '0.3237766035412486',\n",
       " 'eval_metric': 'auc',\n",
       " 'gamma': '6.835606394556246',\n",
       " 'lambda': '313.30483435447155',\n",
       " 'max_delta_step': '7',\n",
       " 'max_depth': '15',\n",
       " 'min_child_weight': '3',\n",
       " 'num_round': '108',\n",
       " 'objective': 'binary:logistic',\n",
       " 'scale_pos_weight': '180',\n",
       " 'subsample': '0.8654307820386923'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
