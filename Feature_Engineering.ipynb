{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as IMBPipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAMEO_DEU_2015_MAP = {\n",
    "    '1A': 1,\n",
    "    '1B': 1,\n",
    "    '1C': 1,\n",
    "    '1D': 1,\n",
    "    '1E': 1,\n",
    "    '2A': 2,\n",
    "    '2B': 2,\n",
    "    '2C': 2,\n",
    "    '2D': 2,\n",
    "    '3A': 3,\n",
    "    '3B': 3,\n",
    "    '3C': 3,\n",
    "    '3D': 3,\n",
    "    '4A': 4,\n",
    "    '4B': 4,\n",
    "    '4C': 4,\n",
    "    '4D': 4,\n",
    "    '4E': 4,\n",
    "    '5A': 5,\n",
    "    '5B': 5,\n",
    "    '5C': 5,\n",
    "    '5D': 5,\n",
    "    '5E': 5,\n",
    "    '5F': 5,\n",
    "    '6A': 6,\n",
    "    '6B': 6,\n",
    "    '6C': 6,\n",
    "    '6D': 6,\n",
    "    '6E': 6,\n",
    "    '6F': 6,\n",
    "    '7A': 7,\n",
    "    '7B': 7,\n",
    "    '7C': 7,\n",
    "    '7D': 7,\n",
    "    '7E': 7,\n",
    "    '8A': 8,\n",
    "    '8B': 8,\n",
    "    '8C': 8,\n",
    "    '8D': 8,\n",
    "    '9A': 9,\n",
    "    '9B': 9,\n",
    "    '9C': 9,\n",
    "    '9D': 9,\n",
    "    '9E': 9\n",
    "}\n",
    "\n",
    "PRAEGENDE_JUGENDJAHRE_MAP = {\n",
    "    1: 0,\n",
    "    2: 1,\n",
    "    3: 0,\n",
    "    4: 1,\n",
    "    5: 0,\n",
    "    6: 1,\n",
    "    7: 1,\n",
    "    8: 0,\n",
    "    9: 1,\n",
    "    10: 0,\n",
    "    11: 1,\n",
    "    12: 0,\n",
    "    13: 1,\n",
    "    14: 0,\n",
    "    15: 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/Udacity_MAILOUT_052018_TRAIN.csv', sep=';', index_col='LNR', low_memory=False)\n",
    "test_df = pd.read_csv('data/Udacity_MAILOUT_052018_TEST.csv', sep=';', index_col='LNR', low_memory=False)\n",
    "metadata = pd.read_csv('data/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_order(val, mx, mn):\n",
    "    diff_from_low = val - mn \n",
    "    return mx - diff_from_low\n",
    "\n",
    "\n",
    "def default_clean(df, drop_threshold=20, testing=False):\n",
    "    df_ = df.copy()\n",
    "    \n",
    "    print('initial df shape: ', df_.shape)\n",
    "    keep_features = list(metadata[metadata['keep'] == 1]['feature_name'])\n",
    "    if 'RESPONSE' in df.columns:\n",
    "        keep_features.append('RESPONSE')\n",
    "    df_ = df_[keep_features]\n",
    "    \n",
    "    filter_ = df_['CAMEO_DEUG_2015'] != np.nan\n",
    "    df_.loc[filter_, 'CAMEO_DEUG_2015'] = pd.to_numeric(df_.loc[filter_, 'CAMEO_DEUG_2015'], errors='coerce')\n",
    "    \n",
    "    # set zero to negative one where zero means unknown\n",
    "    unknown_zero_features = list(metadata[metadata['unknown_zero'] == 1]['feature_name'])\n",
    "    for feature in unknown_zero_features:\n",
    "        df_.loc[df_[feature] == 0, feature] = -1\n",
    "        \n",
    "    # set nine to negative one where nine means unknown\n",
    "    unknown_nine_features = list(metadata[metadata['unknown_nine'] == 1]['feature_name'])\n",
    "    for feature in unknown_nine_features:\n",
    "        df_.loc[df_[feature] == 9, feature] = -1\n",
    "        \n",
    "        \n",
    "    # special cases\n",
    "    df_['CAMEO_DEUG_2015'].replace('X', np.nan, inplace=True)\n",
    "    #df_['OST_WEST_KZ'].replace('O', 1, inplace=True)\n",
    "    #df_['OST_WEST_KZ'].replace('W', 0, inplace=True)    \n",
    "    df_['CAMEO_DEU_2015'] = df_['CAMEO_DEU_2015'].apply(lambda x: x if x in CAMEO_DEU_2015_MAP else np.nan)\n",
    "    df_['PRAEGENDE_JUGENDJAHRE'] = df_['PRAEGENDE_JUGENDJAHRE'].apply(lambda x: PRAEGENDE_JUGENDJAHRE_MAP[x] if x in PRAEGENDE_JUGENDJAHRE_MAP else np.nan)\n",
    "    \n",
    "    # set -1 (unknown) to np.nan\n",
    "    df_ = df_.replace(-1, np.nan)\n",
    "    \n",
    "    \n",
    "    # change some numerical columns to categorical for one hot encoding:\n",
    "    cat_cols = list(metadata.loc[(metadata['type'] == 'categorical') & (metadata['keep'] == 1), 'feature_name'])\n",
    "    print('cat_cols: ', cat_cols)\n",
    "    for col in cat_cols:\n",
    "        if col in df_.columns:\n",
    "            df_[col] = np.where(df_[col].isnull(), df_[col], df_[col].astype('str'))\n",
    "    df_ = pd.get_dummies(df_, prefix=cat_cols, columns=cat_cols)\n",
    "    \n",
    "    # reverse some cols so higher number = higher feature\n",
    "    reverse_cols = list(metadata.loc[metadata['needs_reverse']==1, 'feature_name'])\n",
    "    for col in reverse_cols:\n",
    "        if col in df_.columns:\n",
    "            series = df_[col]\n",
    "            df_[col] = df_[col].apply(reverse_order, args=(np.max(series), np.min(series)))\n",
    "            \n",
    "            \n",
    "    percent_missing = df_.isnull().sum() * 100 / len(df)\n",
    "    mv_df = pd.DataFrame({'column_name': df_.columns, 'percent_missing': percent_missing})\n",
    "    mv_cols = mv_df.loc[mv_df['percent_missing'] > drop_threshold]['column_name']    \n",
    "    df_ = df_.drop(list(mv_cols), axis=1)\n",
    "    \n",
    "    if False:\n",
    "        thresh = int(len(df_.columns) * 0.85)\n",
    "        if 'RESPONSE' in df_.columns:\n",
    "            grouped = df_.groupby(df_.RESPONSE)\n",
    "            pos = grouped.get_group(1)\n",
    "            neg = grouped.get_group(0)\n",
    "            neg = neg.dropna(thresh=thresh)\n",
    "            df_  = neg.append(pos, verify_integrity=True, ignore_index=False)\n",
    "        else:\n",
    "            df_ = df_.dropna(thresh=thresh)\n",
    "        \n",
    "    #df_ = df_.loc[:, ~df_.columns.str.startswith('KB')]\n",
    "    \n",
    "    print('new df shape: ', df_.shape)\n",
    "    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532\n",
      "initial df shape:  (42962, 366)\n",
      "cat_cols:  ['ANREDE_KZ', 'CAMEO_DEU_2015', 'D19_KONSUMTYP', 'GEBAEUDETYP', 'GEBAEUDETYP_RASTER', 'GFK_URLAUBERTYP', 'GREEN_AVANTGARDE', 'HEALTH_TYP', 'KBA05_HERSTTEMP', 'KBA05_MAXHERST', 'KBA05_MODTEMP', 'KBA05_SEG6', 'KONSUMNAEHE', 'NATIONALITAET_KZ', 'OST_WEST_KZ', 'PRAEGENDE_JUGENDJAHRE', 'TITEL_KZ', 'VERS_TYP', 'ZABEOTYP']\n",
      "new df shape:  (42962, 377)\n",
      "initial df shape:  (42833, 365)\n",
      "cat_cols:  ['ANREDE_KZ', 'CAMEO_DEU_2015', 'D19_KONSUMTYP', 'GEBAEUDETYP', 'GEBAEUDETYP_RASTER', 'GFK_URLAUBERTYP', 'GREEN_AVANTGARDE', 'HEALTH_TYP', 'KBA05_HERSTTEMP', 'KBA05_MAXHERST', 'KBA05_MODTEMP', 'KBA05_SEG6', 'KONSUMNAEHE', 'NATIONALITAET_KZ', 'OST_WEST_KZ', 'PRAEGENDE_JUGENDJAHRE', 'TITEL_KZ', 'VERS_TYP', 'ZABEOTYP']\n",
      "new df shape:  (42833, 376)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.sum(train_df['RESPONSE'] == 1))\n",
    "train_df_init = default_clean(train_df, drop_threshold=80)\n",
    "test_df_init = default_clean(test_df, drop_threshold=80, testing=True)\n",
    "np.sum(train_df_init['RESPONSE'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>composition</th>\n",
       "      <th>mu0</th>\n",
       "      <th>mu1</th>\n",
       "      <th>se0</th>\n",
       "      <th>se1</th>\n",
       "      <th>sd</th>\n",
       "      <th>mu_diff</th>\n",
       "      <th>stds_between</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGER_TYP</td>\n",
       "      <td>1</td>\n",
       "      <td>1.698736</td>\n",
       "      <td>1.712991</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>0.035510</td>\n",
       "      <td>0.035761</td>\n",
       "      <td>0.014255</td>\n",
       "      <td>0.398631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALTERSKATEGORIE_GROB</td>\n",
       "      <td>1</td>\n",
       "      <td>3.513077</td>\n",
       "      <td>3.235405</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>0.045459</td>\n",
       "      <td>0.045653</td>\n",
       "      <td>0.277672</td>\n",
       "      <td>6.082289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALTER_HH</td>\n",
       "      <td>1</td>\n",
       "      <td>12.431288</td>\n",
       "      <td>11.658470</td>\n",
       "      <td>0.025466</td>\n",
       "      <td>0.210338</td>\n",
       "      <td>0.211874</td>\n",
       "      <td>0.772818</td>\n",
       "      <td>3.647532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANZ_HAUSHALTE_AKTIV</td>\n",
       "      <td>1</td>\n",
       "      <td>6.652886</td>\n",
       "      <td>5.831435</td>\n",
       "      <td>0.081977</td>\n",
       "      <td>0.569530</td>\n",
       "      <td>0.575400</td>\n",
       "      <td>0.821451</td>\n",
       "      <td>1.427617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANZ_HH_TITEL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048276</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.014012</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>0.018391</td>\n",
       "      <td>1.298842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature  composition        mu0        mu1       se0  \\\n",
       "0              AGER_TYP            1   1.698736   1.712991  0.004230   \n",
       "1  ALTERSKATEGORIE_GROB            1   3.513077   3.235405  0.004203   \n",
       "2              ALTER_HH            1  12.431288  11.658470  0.025466   \n",
       "3   ANZ_HAUSHALTE_AKTIV            1   6.652886   5.831435  0.081977   \n",
       "4          ANZ_HH_TITEL            1   0.048276   0.066667  0.002037   \n",
       "\n",
       "        se1        sd   mu_diff  stds_between  \n",
       "0  0.035510  0.035761  0.014255      0.398631  \n",
       "1  0.045459  0.045653  0.277672      6.082289  \n",
       "2  0.210338  0.211874  0.772818      3.647532  \n",
       "3  0.569530  0.575400  0.821451      1.427617  \n",
       "4  0.014012  0.014159  0.018391      1.298842  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('experimentation/interactions.csv', low_memory=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scaled_diff'] = df['stds_between'] \n",
    "df.loc[df['composition']==2, 'scaled_diff'] = np.sqrt(df.loc[df['composition']==2,'scaled_diff'])\n",
    "df = df.sort_values('scaled_diff', ascending=False)\n",
    "scaled_df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>composition</th>\n",
       "      <th>mu0</th>\n",
       "      <th>mu1</th>\n",
       "      <th>se0</th>\n",
       "      <th>se1</th>\n",
       "      <th>sd</th>\n",
       "      <th>mu_diff</th>\n",
       "      <th>stds_between</th>\n",
       "      <th>scaled_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D19_KONSUMTYP_9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.179843</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.008053</td>\n",
       "      <td>0.008321</td>\n",
       "      <td>0.144129</td>\n",
       "      <td>17.320914</td>\n",
       "      <td>17.320914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KBA05_SEG6_0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.863580</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.020794</td>\n",
       "      <td>0.020878</td>\n",
       "      <td>0.220722</td>\n",
       "      <td>10.572170</td>\n",
       "      <td>10.572170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NATIONALITAET_KZ_1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956607</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.017272</td>\n",
       "      <td>0.017308</td>\n",
       "      <td>0.153975</td>\n",
       "      <td>8.896222</td>\n",
       "      <td>8.896222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FINANZ_UNAUFFAELLIGER</td>\n",
       "      <td>1</td>\n",
       "      <td>4.324496</td>\n",
       "      <td>3.766917</td>\n",
       "      <td>0.005152</td>\n",
       "      <td>0.062659</td>\n",
       "      <td>0.062870</td>\n",
       "      <td>0.557579</td>\n",
       "      <td>8.868726</td>\n",
       "      <td>8.868726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEMIO_REL</td>\n",
       "      <td>1</td>\n",
       "      <td>5.228081</td>\n",
       "      <td>4.582707</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.090337</td>\n",
       "      <td>0.090727</td>\n",
       "      <td>0.645374</td>\n",
       "      <td>7.113352</td>\n",
       "      <td>7.113352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature  composition       mu0       mu1       se0       se1  \\\n",
       "0      D19_KONSUMTYP_9.0            1  0.179843  0.035714  0.002094  0.008053   \n",
       "1         KBA05_SEG6_0.0            1  0.863580  0.642857  0.001871  0.020794   \n",
       "2   NATIONALITAET_KZ_1.0            1  0.956607  0.802632  0.001111  0.017272   \n",
       "3  FINANZ_UNAUFFAELLIGER            1  4.324496  3.766917  0.005152  0.062659   \n",
       "4              SEMIO_REL            1  5.228081  4.582707  0.008403  0.090337   \n",
       "\n",
       "         sd   mu_diff  stds_between  scaled_diff  \n",
       "0  0.008321  0.144129     17.320914    17.320914  \n",
       "1  0.020878  0.220722     10.572170    10.572170  \n",
       "2  0.017308  0.153975      8.896222     8.896222  \n",
       "3  0.062870  0.557579      8.868726     8.868726  \n",
       "4  0.090727  0.645374      7.113352     7.113352  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(n):\n",
    "    return scaled_df.loc[0:n,['feature', 'composition']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_sets(top_n=None):\n",
    "\n",
    "    X_train_full = train_df_init.copy()\n",
    "    y_train_full = X_train_full['RESPONSE']\n",
    "\n",
    "    inter_cols = list(set.intersection(set(X_train_full.columns), set(test_df_init.columns)))\n",
    "\n",
    "    X_train_full = X_train_full[inter_cols]\n",
    "\n",
    "    # \"Cardinality\" means the number of unique values in a column\n",
    "    # Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "    categorical_cols = [cname for cname in X_train_full.columns if\n",
    "                        X_train_full[cname].nunique() < 15 and\n",
    "                        X_train_full[cname].nunique() >= 2 and\n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "\n",
    "    # Select numerical columns\n",
    "    numerical_cols = [cname for cname in X_train_full.columns if \n",
    "                    X_train_full[cname].dtype in ['int64', 'float64', 'uint8']]\n",
    "    \n",
    "    if top_n:\n",
    "        features = get_top_n(top_n)\n",
    "        numerical_cols = []\n",
    "        for ix, row in features.iterrows():\n",
    "            comp = row['composition']\n",
    "            f = row['feature']\n",
    "            numerical_cols.append(f)\n",
    "            if comp == 2:\n",
    "                fs = f.split(':')\n",
    "                f0 = fs[0]\n",
    "                f1 = fs[1]\n",
    "                test_df_init[f] = test_df_init[f0] * test_df_init[f1]\n",
    "                train_df_init[f] = train_df_init[f0] * train_df_init[f1]\n",
    "                \n",
    "\n",
    "                \n",
    "\n",
    "    # Keep selected columns only\n",
    "    my_cols = numerical_cols + categorical_cols\n",
    "\n",
    "    # supervised testing and full datasets\n",
    "    X_test = test_df_init[my_cols].copy()\n",
    "    X_total_train = train_df_init[my_cols].copy()\n",
    "    y_total_train = train_df_init['RESPONSE'].copy()\n",
    "\n",
    "    assert(list(X_total_train.columns) == list(X_test.columns))\n",
    "    \n",
    "    return X_total_train, y_total_train, X_test, numerical_cols, categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total_train, y_total_train, X_test, numerical_cols, categorical_cols = get_initial_sets(500)\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "   # ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC: 0.7319654249784922\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight='auto', max_iter=300)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('scaling', MinMaxScaler()),\n",
    "                              ('pca', PCA(n_components=450)),\n",
    "                              ('model', model)\n",
    "                     ])\n",
    "\n",
    "# Multiply by -1 since sklearn calculates *negative* MAE\n",
    "scores = cross_val_score(my_pipeline, X_total_train, y_total_train,\n",
    "                              cv=5,\n",
    "                              scoring='roc_auc')\n",
    "\n",
    "print('Mean AUC:', scores.mean())\n",
    "\n",
    "# has AUC of 0.6283"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=180, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)\n",
      "Mean AUC: 0.6705251220666832\n",
      "BalancedRandomForestClassifier(n_jobs=-1)\n",
      "Mean AUC: 0.6540242731989659\n",
      "BalancedBaggingClassifier()\n",
      "Mean AUC: 0.6028139982486117\n",
      "HistGradientBoostingClassifier()\n",
      "Mean AUC: 0.6371716370170076\n"
     ]
    }
   ],
   "source": [
    "models = [xgb.XGBClassifier(scale_pos_weight=180, n_jobs=-1), BalancedRandomForestClassifier(n_jobs=-1), \n",
    "          BalancedBaggingClassifier(), HistGradientBoostingClassifier()]\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    print(model)\n",
    "    my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                  ('model', model)\n",
    "                         ])\n",
    "    \n",
    "    scores = cross_val_score(my_pipeline, X_total_train, y_total_train,\n",
    "                              cv=5,\n",
    "                              scoring='roc_auc')\n",
    "    \n",
    "    print('Mean AUC:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC: 0.657969803116966\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(scale_pos_weight=180,\n",
    "                          n_jobs=-1,\n",
    "                          alpha=440,\n",
    "                          reg_lambda=313,\n",
    "                          min_child_weight=3,\n",
    "                          max_depth=15,\n",
    "                          learning_rate=0.3,\n",
    "                          subsample=0.87,\n",
    "                          max_delta_step=7,\n",
    "                          n_estimators=110,\n",
    "                          gamma=6.83,\n",
    "                          colsample_bylevel=0.35,\n",
    "                          colsample_bynode=0.13,\n",
    "                          colsample_bytree=0.56)\n",
    "                          \n",
    "\n",
    "\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)\n",
    "                     ])\n",
    "\n",
    "scores = cross_val_score(my_pipeline, X_total_train, y_total_train,\n",
    "                          cv=5,\n",
    "                          scoring='roc_auc')\n",
    "\n",
    "print('Mean AUC:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42833, 2)\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(scale_pos_weight=180,\n",
    "                          n_jobs=-1,\n",
    "                          alpha=440,\n",
    "                          reg_lambda=313,\n",
    "                          min_child_weight=3,\n",
    "                          max_depth=15,\n",
    "                          learning_rate=0.3,\n",
    "                          subsample=0.87,\n",
    "                          max_delta_step=7,\n",
    "                          n_estimators=110,\n",
    "                          gamma=6.83,\n",
    "                          colsample_bylevel=0.35,\n",
    "                          colsample_bynode=0.13,\n",
    "                          colsample_bytree=0.56)\n",
    "\n",
    "\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "X_total_fit = my_pipeline.fit_transform(X_total_train)\n",
    "model.fit(X_total_fit, y_total_train)\n",
    "                       \n",
    "X_test_fit = my_pipeline.transform(X_test)\n",
    "preds = model.predict_proba(X_test_fit)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RESPONSE\n",
      "LNR           \n",
      "1754  0.708098\n",
      "1770  0.797928\n",
      "1465  0.192424\n",
      "1470  0.188132\n",
      "1478  0.711915\n"
     ]
    }
   ],
   "source": [
    "preds_0 = preds[:,1]\n",
    "tester_df = pd.DataFrame(preds_0, index=X_test.index, columns=['RESPONSE'])\n",
    "print(tester_df.head())\n",
    "tester_df.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
